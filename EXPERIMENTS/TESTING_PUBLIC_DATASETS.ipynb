{"cells":[{"cell_type":"code","source":["# pip install pymysql"],"metadata":{"id":"-L3c2KkjOlB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19073,"status":"ok","timestamp":1655033207654,"user":{"displayName":"niyaz ismail","userId":"05553853388840158157"},"user_tz":-180},"id":"GzmjrY-VRAkp","outputId":"478b937a-16b3-4080-aa4a-446a006654e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cq0OXI62uxkJ"},"outputs":[],"source":["%run /content/drive/MyDrive/Colab\\ Notebooks/implementation/packages/Basic.ipynb"]},{"cell_type":"code","source":["import json\n","import csv\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection    import cross_validate,KFold, train_test_split\n","from sklearn.metrics            import classification_report, confusion_matrix,ConfusionMatrixDisplay,f1_score,recall_score, precision_score, accuracy_score,roc_auc_score\n","from sklearn.ensemble           import RandomForestClassifier,BaggingClassifier, IsolationForest, ExtraTreesClassifier,AdaBoostClassifier, GradientBoostingClassifier\n","\n","from sklearn.feature_selection  import mutual_info_classif,f_classif, SelectKBest,RFE,SelectFromModel\n","from sklearn.metrics import f1_score,recall_score, precision_score, accuracy_score,roc_auc_score\n","\n","\n","from sklearn.datasets           import make_classification\n","from sklearn.tree               import DecisionTreeClassifier\n","from xgboost                    import XGBClassifier\n","from sklearn.neighbors          import KNeighborsClassifier\n","from sklearn.naive_bayes        import GaussianNB\n","\n","\n","from sklearn.preprocessing      import QuantileTransformer\n","\n","\n","from sklearn.covariance         import EllipticEnvelope\n","from sklearn.neighbors          import LocalOutlierFactor\n","from sklearn.svm                import OneClassSVM, SVC\n","\n","\n","\n","from sklearn.linear_model       import LogisticRegression\n","from sklearn.pipeline           import Pipeline\n","\n","import sqlalchemy\n","from urllib.parse import quote"],"metadata":{"id":"nzsYDTF-xUZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(f'PATH/selectedModelsData.json') as data_file:    \n","    modelFile = json.load(data_file) \n","\n","selectedModels = pd.json_normalize(modelFile,max_level=0)\n","\n","selectedModels.rename(columns={'Model Name':'modelName'}, inplace=True)"],"metadata":{"id":"UZgmrE4J0-aH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selectedModels.drop(columns=[\"id\"],axis=1,inplace=True)\n","selectedModels.head(11)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"p3giiPgD4f9k","executionInfo":{"status":"ok","timestamp":1654989174980,"user_tz":-180,"elapsed":304,"user":{"displayName":"niyaz ismail","userId":"05553853388840158157"}},"outputId":"967aab06-d70f-4c90-fdcb-dd281bef56ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   featureNumber modelName      selectionMethod  \\\n","0             10    et_500     rfe_DecisionTree   \n","1             10    et_100     rfe_DecisionTree   \n","2             10    rf_100     rfe_DecisionTree   \n","3             10    rf_500     rfe_DecisionTree   \n","4             10    bc_100     rfe_DecisionTree   \n","5             10       xgb     rfe_DecisionTree   \n","6             10    et_500  mutual_info_classif   \n","7             10    rf_500  mutual_info_classif   \n","8             10    et_100      sf_RandomForest   \n","9             10    et_500      sf_RandomForest   \n","10            15       xgb     rfe_DecisionTree   \n","\n","                                     selectedFeatures  \n","0   [['description_length', 'favourites_count', 'f...  \n","1   [['Name_entropy', 'favourites_count', 'favouri...  \n","2   [['description_length', 'favourites_count', 'f...  \n","3   [['Name_entropy', 'favourites_count', 'favouri...  \n","4   [['description_length', 'favourites_count', 'f...  \n","5   [['Name_similarity', 'description_length', 'fa...  \n","6   [['diff_days', 'favourites_count', 'favourites...  \n","7   [['diff_days', 'favourites_count', 'favourites...  \n","8   [['diff_days', 'favourites_count', 'favourites...  \n","9   [['diff_days', 'favourites_count', 'favourites...  \n","10  [['Name_entropy', 'Screen_name_entropy', 'desc...  "],"text/html":["\n","  <div id=\"df-0070119c-43ea-467d-b4d9-6685ae805484\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>featureNumber</th>\n","      <th>modelName</th>\n","      <th>selectionMethod</th>\n","      <th>selectedFeatures</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10</td>\n","      <td>et_500</td>\n","      <td>rfe_DecisionTree</td>\n","      <td>[['description_length', 'favourites_count', 'f...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10</td>\n","      <td>et_100</td>\n","      <td>rfe_DecisionTree</td>\n","      <td>[['Name_entropy', 'favourites_count', 'favouri...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","      <td>rf_100</td>\n","      <td>rfe_DecisionTree</td>\n","      <td>[['description_length', 'favourites_count', 'f...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10</td>\n","      <td>rf_500</td>\n","      <td>rfe_DecisionTree</td>\n","      <td>[['Name_entropy', 'favourites_count', 'favouri...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10</td>\n","      <td>bc_100</td>\n","      <td>rfe_DecisionTree</td>\n","      <td>[['description_length', 'favourites_count', 'f...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10</td>\n","      <td>xgb</td>\n","      <td>rfe_DecisionTree</td>\n","      <td>[['Name_similarity', 'description_length', 'fa...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10</td>\n","      <td>et_500</td>\n","      <td>mutual_info_classif</td>\n","      <td>[['diff_days', 'favourites_count', 'favourites...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10</td>\n","      <td>rf_500</td>\n","      <td>mutual_info_classif</td>\n","      <td>[['diff_days', 'favourites_count', 'favourites...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>10</td>\n","      <td>et_100</td>\n","      <td>sf_RandomForest</td>\n","      <td>[['diff_days', 'favourites_count', 'favourites...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>et_500</td>\n","      <td>sf_RandomForest</td>\n","      <td>[['diff_days', 'favourites_count', 'favourites...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>15</td>\n","      <td>xgb</td>\n","      <td>rfe_DecisionTree</td>\n","      <td>[['Name_entropy', 'Screen_name_entropy', 'desc...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0070119c-43ea-467d-b4d9-6685ae805484')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0070119c-43ea-467d-b4d9-6685ae805484 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0070119c-43ea-467d-b4d9-6685ae805484');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["##VERSION 1"],"metadata":{"id":"4QvOrzbWyjeO"}},{"cell_type":"code","source":["connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.format('USER',quote('PASS'),'IP','DB'))\n","\n","model_result=[\"outLierModel\",\"removedSample\",\"featureNumber\",\"DataSet\",\"modelName\",\"selectionMethod\",\"selectedFeatures\",\"Train_Accuracy\",\"Train_F1\",\"Train_Precision\",\"Train_Recall\",\"Train_AUC\",\"Test_Accuracy\",\"Test_F1\",\"Test_Precision\",\"Test_Recall\",\"Test_AUC\"]\n","\n","\n","\n","with open(f'PATH/selectedModelsData.json') as data_file:    \n","    modelFile = json.load(data_file) \n","\n","selectedModels = pd.json_normalize(modelFile,max_level=0)\n","selectedModels.rename(columns={'Model Name':'modelName'}, inplace=True)\n","\n","\n","data = pd.read_csv(f'PATH/DS1.csv.gz',compression='gzip',lineterminator='\\n');\n","data=data.sample(frac=1).reset_index(drop=True)\n","# data=data.loc[0:100,:]\n","\n","\n","ModelsList={\n","    \"xgb\":XGBClassifier(),\n","    \"ab\":AdaBoostClassifier(),\n","    \"gn\":GaussianNB(),\n","    \"lr\":LogisticRegression(solver='lbfgs',max_iter=1000),\n","    \"rf_100\":RandomForestClassifier(n_estimators=100),\n","    \"dt\":DecisionTreeClassifier(),\n","    \"et_100\":ExtraTreesClassifier(n_estimators=100),\n","    \"knn3\":KNeighborsClassifier(n_neighbors=3),\n","    \"knn5\":KNeighborsClassifier(n_neighbors=5),\n","    \"svc_n\":SVC(),\n","    \"bc_100\":BaggingClassifier(n_estimators=100),\n","    \"et_500\":ExtraTreesClassifier(n_estimators=500),\n","    \"rf_500\":RandomForestClassifier(n_estimators=500),\n","}\n","\n","datasets=[\"DS4\",\"DS5\",\"DS6\",\"DS7\",\"DS12\",\"DS13\",\"DS14\",\"DS16\"]\n","testDataSet={}\n","for index,dataset in enumerate(datasets):\n","    testDataSet[dataset] = pd.read_csv(f'/content/drive/MyDrive/DATA/MetaData/Test/{dataset}.csv.gz',compression='gzip',lineterminator='\\n');\n","    testDataSet[dataset]=testDataSet[dataset].sample(frac=1).reset_index(drop=True)\n","\n","\n","normalizingModels=QuantileTransformer(output_distribution=\"normal\",n_quantiles=100)\n","\n","outlierMethod={\n","        \"all\":\"\",\n","        \"iso\":IsolationForest(contamination=0.1),\n","        \"ee\":EllipticEnvelope(contamination=0.01),\n","        \"lof\":LocalOutlierFactor(),\n","        \"ncSVM\":OneClassSVM(nu=0.01)\n","}\n","\n","for index, row in selectedModels.iterrows():\n","    \n","    # Converting str to json\n","    featureList=json.loads(row[\"selectedFeatures\"].replace(\"'\",'\"'));\n","\n","    #find the average number of features for each cross-validation (for 10 features selection the total sometime is 8,9, or 10)\n","    numberOfFeatues=int(np.mean(list(map(len,featureList))));\n","\n","    # Find the total number for each unique values\n","    unique, counts = np.unique(np.hstack(featureList), return_counts=True)\n","    sortValue=np.asarray((unique, counts)).T\n","\n","    # select the best average features\n","    SelectedFeatures=sortValue[np.flip(np.argsort(sortValue[:, 1]))][0:numberOfFeatues,0]\n","\n","    # print(len(SelectedFeatures),SelectedFeatures)\n","    X = normalizingModels.fit_transform(data[SelectedFeatures])\n","    y = data['class'].map({\"bot\": 1, \"human\": 0});\n","    \n","    for keyOutlier,valueOutlier in outlierMethod.items():\n","\n","        if keyOutlier!=\"all\":\n","            outlierPrediction=(valueOutlier.fit_predict(X)!= -1)\n","            X= X[outlierPrediction]\n","            y=y[outlierPrediction]\n","\n","        model = ModelsList[row[\"modelName\"]]\n","        model.fit(X, y)\n","        \n","        for keyTest,dataTest in testDataSet.items():\n","\n","            testX=dataTest\n","            testY=testX[\"class\"].map({\"bot\": 1, \"human\": 0});\n","            testX=QuantileTransformer(output_distribution=\"normal\",n_quantiles=50).fit_transform(testX[SelectedFeatures])\n","\n","            if keyOutlier!=\"all\":\n","                outlierPrediction=(valueOutlier.fit_predict(testX)!= -1)\n","                testX= testX[outlierPrediction]\n","                testY=testY[outlierPrediction]\n","\n","            pd.DataFrame (\n","                [[\n","                    keyOutlier,\n","                    (len(data)-len(X)),\n","                    row[\"featureNumber\"],\n","                    keyTest,\n","                    row[\"modelName\"],\n","                    row[\"selectionMethod\"],\n","                    json.dumps(SelectedFeatures.tolist()),\n","                    accuracy_score(y, model.predict(X)),\n","                    f1_score(y, model.predict(X)),\n","                    precision_score(y, model.predict(X)),\n","                    recall_score(y, model.predict(X)),\n","                    roc_auc_score(y, model.predict(X)),\n","                    accuracy_score(testY, model.predict(testX)),\n","                    f1_score(testY, model.predict(testX)),\n","                    precision_score(testY, model.predict(testX)),\n","                    recall_score(testY, model.predict(testX)),\n","                    roc_auc_score(testY, model.predict(testX))\n","                ]],\n","                columns=model_result\n","            ).to_sql(con=connection, name='generalization_test_1', if_exists='append',index = False)"],"metadata":{"id":"Gf2ozt9EzySn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##VERSION 2"],"metadata":{"id":"3-uFo5_qygQQ"}},{"cell_type":"code","source":["connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.format('USER',quote('PASS'),'IP','DB'))\n","\n","\n","ModelsList={\n","    \"xgb\":XGBClassifier(),\n","    \"ab\":AdaBoostClassifier(),\n","    \"gn\":GaussianNB(),\n","    \"lr\":LogisticRegression(solver='lbfgs',max_iter=1000),\n","    \"rf_100\":RandomForestClassifier(n_estimators=100),\n","    \"dt\":DecisionTreeClassifier(),\n","    \"et_100\":ExtraTreesClassifier(n_estimators=100),\n","    \"knn3\":KNeighborsClassifier(n_neighbors=3),\n","    \"knn5\":KNeighborsClassifier(n_neighbors=5),\n","    \"svc_n\":SVC(),\n","    \"bc_100\":BaggingClassifier(n_estimators=100),\n","    \"et_500\":ExtraTreesClassifier(n_estimators=500),\n","    \"rf_500\":RandomForestClassifier(n_estimators=500),\n","}\n","\n","datasets=[\"DS4\",\"DS5\",\"DS6\",\"DS7\",\"DS12\",\"DS13\",\"DS14\",\"DS16\"]\n","testDataSet={}\n","for index,dataset in enumerate(datasets):\n","  testDataSet[dataset] = pd.read_csv(f'PATH/{dataset}.csv.gz',compression='gzip',lineterminator='\\n');\n","  testDataSet[dataset]=testDataSet[dataset].sample(frac=1).reset_index(drop=True)\n","\n","normalizingModels=QuantileTransformer(output_distribution=\"normal\",n_quantiles=100)\n","\n","\n","for index, row in selectedModels.iterrows():\n","    \n","    # Converting str to json\n","    featureList=json.loads(row[\"selectedFeatures\"].replace(\"'\",'\"'));\n","\n","    #find the average number of features for each cross-validation (for 10 features selection the total sometime is 8,9, or 10)\n","    numberOfFeatues=int(np.mean(list(map(len,featureList))));\n","\n","    # Find the total number for each unique values\n","    unique, counts = np.unique(np.hstack(featureList), return_counts=True)\n","    sortValue=np.asarray((unique, counts)).T\n","\n","\n","    # select the best average features\n","    SelectedFeatures=sortValue[np.flip(np.argsort(sortValue[:, 1]))][0:numberOfFeatues,0]\n","\n","\n","    X = normalizingModels.fit_transform(data[SelectedFeatures])\n","\n","    y = data['class'].map({\"bot\": 1, \"human\": 0});\n","\n","\n","    model_result=[\"featureNumber\",\"DataSet\",\"modelName\",\"selectionMethod\",\"selectedFeatures\",\"Train_Accuracy\",\"Train_F1\",\"Train_Precision\",\"Train_Recall\",\"Train_AUC\",\"Test_Accuracy\",\"Test_F1\",\"Test_Precision\",\"Test_Recall\",\"Test_AUC\"]\n","\n","\n","    model = ModelsList[row[\"modelName\"]]\n","    model.fit(X, y)\n","      \n","    for keyTest,dataTest in testDataSet.items():\n","\n","        dataTest=dataTest.sample(frac=1).reset_index(drop=True)\n","        testX=dataTest.loc[0:50,:]\n","        testY=testX[\"class\"].map({\"bot\": 1, \"human\": 0});\n","        testX=QuantileTransformer(output_distribution=\"normal\",n_quantiles=50).fit_transform(testX[SelectedFeatures])\n","    \n","\n","        pd.DataFrame (\n","            [[\n","                row[\"featureNumber\"],\n","                keyTest,\n","                row[\"modelName\"],\n","                row[\"selectionMethod\"],\n","                json.dumps(SelectedFeatures.tolist()),\n","                accuracy_score(y, model.predict(X)),\n","                f1_score(y, model.predict(X)),\n","                precision_score(y, model.predict(X)),\n","                recall_score(y, model.predict(X)),\n","                roc_auc_score(y, model.predict(X)),\n","                accuracy_score(testY, model.predict(testX)),\n","                f1_score(testY, model.predict(testX)),\n","                precision_score(testY, model.predict(testX)),\n","                recall_score(testY, model.predict(testX)),\n","                roc_auc_score(testY, model.predict(testX))\n","            ]],\n","            columns=model_result\n","        ).to_sql(con=connection, name='generalization_test_1', if_exists='append',index = False)"],"metadata":{"id":"BUIXdx50Qg3E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#VERSION 3"],"metadata":{"id":"gfbvF8X0ybi_"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score,recall_score, precision_score, accuracy_score,roc_auc_score\n","connection = sqlalchemy.create_engine('mysql+pymysql://{0}:{1}@{2}/{3}'.format('USER',quote('PASS'),'IP','DB'))\n","\n","\n","ModelsList={\n","    \"xgb\":XGBClassifier(),\n","    \"ab\":AdaBoostClassifier(),\n","    \"gn\":GaussianNB(),\n","    \"lr\":LogisticRegression(solver='lbfgs',max_iter=1000),\n","    \"rf_100\":RandomForestClassifier(n_estimators=100),\n","    \"dt\":DecisionTreeClassifier(),\n","    \"et_100\":ExtraTreesClassifier(n_estimators=100),\n","    \"knn3\":KNeighborsClassifier(n_neighbors=3),\n","    \"knn5\":KNeighborsClassifier(n_neighbors=5),\n","    \"bc_100\":BaggingClassifier(n_estimators=100),\n","    \"et_500\":ExtraTreesClassifier(n_estimators=500),\n","    \"rf_500\":RandomForestClassifier(n_estimators=500),\n","    \"svc_n\":SVC(),\n","}\n","\n","datasets=[\"DS4\",\"DS5\",\"DS6\",\"DS7\",\"DS12\",\"DS13\",\"DS14\",\"DS15\",\"DS16\"]\n","testDataSet={}\n","for index,dataset in enumerate(datasets):\n","  testDataSet[dataset] = pd.read_csv(f'PATH/{dataset}.csv.gz',compression='gzip',lineterminator='\\n');\n","  testDataSet[dataset]=testDataSet[dataset].sample(frac=1).reset_index(drop=True)\n","\n","normalizingModels=QuantileTransformer(output_distribution=\"normal\",n_quantiles=len(data))\n","\n","\n","\n","SelectedFeatures=[\"Screen_name_freq\",\"Name_similarity\",\"Name_freq\",\"diff_days\",\"name_length\",\"screen_name_length\",\"description_length\",\"num_digits_in_name\",\"Name_entropy\",\"Screen_name_entropy\"]\n","X = normalizingModels.fit_transform(data[SelectedFeatures])\n","y = data['class'].map({\"bot\": 1, \"human\": 0});\n","model_result=[\"modelName\",\"featureNumber\",\"DataSet\",\"Train_Accuracy\",\"Train_F1\",\"Train_Precision\",\"Train_Recall\",\"Train_AUC\",\"Test_Accuracy\",\"Test_F1\",\"Test_Precision\",\"Test_Recall\",\"Test_AUC\"]\n","\n","for keyModel,valueModel in ModelsList.items():\n","\n","    model = valueModel\n","    model.fit(X, y)\n","      \n","    for keyTest,dataTest in testDataSet.items():\n","\n","        testX=dataTest\n","        testY=testX[\"class\"].map({\"bot\": 1, \"human\": 0});\n","        testX=QuantileTransformer(output_distribution=\"normal\",n_quantiles=len(testX)).fit_transform(testX[SelectedFeatures])\n","    \n","\n","        pd.DataFrame (\n","            [[\n","                keyModel,\n","                keyTest,\n","                json.dumps(SelectedFeatures),\n","                accuracy_score(y, model.predict(X)),\n","                f1_score(y, model.predict(X)),\n","                precision_score(y, model.predict(X)),\n","                recall_score(y, model.predict(X)),\n","                roc_auc_score(y, model.predict(X)),\n","                accuracy_score(testY, model.predict(testX)),\n","                f1_score(testY, model.predict(testX)),\n","                precision_score(testY, model.predict(testX)),\n","                recall_score(testY, model.predict(testX)),\n","                roc_auc_score(testY, model.predict(testX))\n","            ]],\n","            columns=model_result\n","        ).to_sql(con=connection, name='test_gn_55', if_exists='append',index = False)"],"metadata":{"id":"qKpZt6MsyacF"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}